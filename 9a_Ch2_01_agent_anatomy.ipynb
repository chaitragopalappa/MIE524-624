{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP4lxTZNwvEG9lNCq1jdaJY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"3kF8svtmJbpA","executionInfo":{"status":"ok","timestamp":1739749515816,"user_tz":300,"elapsed":156,"user":{"displayName":"Chaitra Gopalappa","userId":"05469713652506822347"}}},"outputs":[],"source":["#SOURCE: Ch2_01_agent_anatomy of Deep reinforcement learning Hands-on, by Maxim Lapan https://github.com/packtpublishing/deep-reinforcement-learning-hands-on\n","#USE THIS CODE FOR 2 PURPOSES\n","#..1.....# INTRO TO OBJECT ORIENTED PROGRAMMING: understand  'class' 'object of a class';\n","#..2.....# INTRO TO RL - agent anatomy\n","import random\n","from typing import List"]},{"cell_type":"code","source":["#chnage code such that value of reward = 0 if action =0, 1 if action = 1; and verify if results are correct (increase steps_left to large number\n","#;then check  rewards ~ Steps_left / 2)\n","class Environment:\n","    def __init__(self): #initialize all paramters of the class\n","        self.steps_left = 100000\n","\n","    #class can have multiple functions\n","    def get_observation(self) -> List[float]:\n","        return [0.0, 0.0, 0.0]\n","\n","    def get_actions(self) -> List[int]:\n","        return [0, 1]\n","\n","    def is_done(self) -> bool:\n","        return self.steps_left == 0#returns 1 if steps_left = 0\n","\n","    def action(self, action: int) -> float:\n","        if self.is_done():\n","            raise Exception(\"Game is over\")\n","        self.steps_left -= 1\n","        if action == 0:\n","            val = 0\n","        else:\n","            val = 1\n","        return val"],"metadata":{"id":"Q1XrWxS7JpaI","executionInfo":{"status":"ok","timestamp":1739749517131,"user_tz":300,"elapsed":147,"user":{"displayName":"Chaitra Gopalappa","userId":"05469713652506822347"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class Agent:\n","    def __init__(self):\n","        self.total_reward = 0.0\n","\n","    def step(self, env: Environment):\n","        current_obs = env.get_observation()\n","        actions = env.get_actions()\n","        reward = env.action(random.choice(actions))\n","        self.total_reward += reward"],"metadata":{"id":"B87XIJoTJjyz","executionInfo":{"status":"ok","timestamp":1739749518375,"user_tz":300,"elapsed":174,"user":{"displayName":"Chaitra Gopalappa","userId":"05469713652506822347"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":#this will be called if running this as main script; if instead this module is called from a differnt script this part will not be run\n","    env = Environment() #'object of a class'\n","    agent = Agent()#'object of a class'\n","\n","    while not env.is_done():\n","        agent.step(env)\n","\n","    print(\"Total reward got: %.4f\" % agent.total_reward)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C-vRE85iJlrg","executionInfo":{"status":"ok","timestamp":1739749520182,"user_tz":300,"elapsed":276,"user":{"displayName":"Chaitra Gopalappa","userId":"05469713652506822347"}},"outputId":"09211378-9d80-4670-eaf6-8a848c867d8c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Total reward got: 49897.0000\n"]}]}]}